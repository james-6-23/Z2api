package main

import (
	"bufio"
	"bytes"
	"context"
	"crypto/rand"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"math"
	mathrand "math/rand"
	"net"
	"net/http"
	"os"
	"regexp"
	"runtime"
	"strconv"
	"strings"
	"sync/atomic"
	"time"
)

// ç‰ˆæœ¬ä¿¡æ¯
const (
	VERSION     = "2.1.0"
	BUILD_DATE  = "2025-01-03"
	DESCRIPTION = "Z2API Goä¼˜åŒ–ç‰ˆ - åŸºäºåŸç‰ˆZ2APIçš„ä¼ä¸šçº§ä¼˜åŒ–å®ç°"
)

// ç±»å‹å®šä¹‰
type ChatMessage struct {
	Role             string `json:"role"`
	Content          string `json:"content"`
	ReasoningContent string `json:"reasoning_content,omitempty"`
}

type OpenAIRequest struct {
	Model       string        `json:"model"`
	Messages    []ChatMessage `json:"messages"`
	Stream      *bool         `json:"stream,omitempty"`
	Temperature *float64      `json:"temperature,omitempty"`
	MaxTokens   *int          `json:"max_tokens,omitempty"`
}

type UpstreamRequest struct {
	Stream          bool                   `json:"stream"`
	Model           string                 `json:"model"`
	Messages        []ChatMessage          `json:"messages"`
	Params          map[string]interface{} `json:"params"`
	Features        map[string]interface{} `json:"features"`
	BackgroundTasks map[string]bool        `json:"background_tasks,omitempty"`
	ChatID          string                 `json:"chat_id,omitempty"`
	ID              string                 `json:"id,omitempty"`
	MCPServers      []string               `json:"mcp_servers,omitempty"`
	ModelItem       struct {
		ID      string `json:"id"`
		Name    string `json:"name"`
		OwnedBy string `json:"owned_by"`
	} `json:"model_item,omitempty"`
	ToolServers []string          `json:"tool_servers,omitempty"`
	Variables   map[string]string `json:"variables,omitempty"`
}

type Delta struct {
	Role             string `json:"role,omitempty"`
	Content          string `json:"content,omitempty"`
	ReasoningContent string `json:"reasoning_content,omitempty"`
}

type Choice struct {
	Index        int         `json:"index"`
	Message      ChatMessage `json:"message,omitempty"`
	Delta        Delta       `json:"delta,omitempty"`
	FinishReason string      `json:"finish_reason,omitempty"`
}

type OpenAIResponse struct {
	ID      string   `json:"id"`
	Object  string   `json:"object"`
	Created int64    `json:"created"`
	Model   string   `json:"model"`
	Choices []Choice `json:"choices"`
	Usage   *Usage   `json:"usage,omitempty"`
}

type Usage struct {
	PromptTokens     int `json:"prompt_tokens"`
	CompletionTokens int `json:"completion_tokens"`
	TotalTokens      int `json:"total_tokens"`
}

type UpstreamData struct {
	Type string `json:"type"`
	Data struct {
		DeltaContent string         `json:"delta_content"`
		EditContent  string         `json:"edit_content"`
		Phase        string         `json:"phase"`
		Done         bool           `json:"done"`
		Usage        *Usage         `json:"usage,omitempty"`
		Error        *UpstreamError `json:"error,omitempty"`
		Inner        *struct {
			Error *UpstreamError `json:"error,omitempty"`
		} `json:"data,omitempty"`
	} `json:"data"`
	Error *UpstreamError `json:"error,omitempty"`
}

type UpstreamError struct {
	Detail string `json:"detail"`
	Code   int    `json:"code"`
}

type Model struct {
	ID      string `json:"id"`
	Object  string `json:"object"`
	Created int64  `json:"created"`
	OwnedBy string `json:"owned_by"`
}

type ModelsResponse struct {
	Object string  `json:"object"`
	Data   []Model `json:"data"`
}

// æ—¥å¿—ç³»ç»Ÿç±»å‹å®šä¹‰
type LogLevel string

const (
	LogLevelInfo  LogLevel = "INFO"
	LogLevelWarn  LogLevel = "WARN"
	LogLevelError LogLevel = "ERROR"
)

type RequestLog struct {
	RequestID  string      `json:"request_id"`
	Timestamp  string      `json:"timestamp"`
	Level      LogLevel    `json:"level"`
	Type       string      `json:"type"`
	ClientIP   string      `json:"client_ip"`
	APIKey     string      `json:"api_key"`
	Model      string      `json:"model"`
	Messages   interface{} `json:"messages,omitempty"`
	Parameters interface{} `json:"parameters,omitempty"`
	UserAgent  string      `json:"user_agent,omitempty"`
}

type ResponseLog struct {
	RequestID        string      `json:"request_id"`
	Timestamp        string      `json:"timestamp"`
	Level            LogLevel    `json:"level"`
	Type             string      `json:"type"`
	StatusCode       int         `json:"status_code"`
	ResponseTime     int64       `json:"response_time_ms"`
	Endpoint         string      `json:"endpoint"`
	RetryCount       int         `json:"retry_count"`
	Content          interface{} `json:"content,omitempty"`
	ReasoningContent string      `json:"reasoning_content,omitempty"`
	Error            string      `json:"error,omitempty"`
}

type HealthStats struct {
	TotalRequests       int64 `json:"total_requests"`
	AverageResponseTime int64 `json:"average_response_time"`
	ErrorRate           int   `json:"error_rate"`
	CurrentConnections  int64 `json:"current_connections"`
}

type HealthConfig struct {
	MaxRetries             int    `json:"max_retries"`
	RetryDelay             int    `json:"retry_delay"`
	RequestTimeout         int    `json:"request_timeout"`
	RandomDelay            string `json:"random_delay"`
	MaxConcurrentConns     int    `json:"max_concurrent_connections"`
	StreamBufferSize       int    `json:"stream_buffer_size"`
	ConnectionCheckEnabled bool   `json:"connection_check_enabled"`
}

type HealthResponse struct {
	Status          string       `json:"status"`
	Timestamp       string       `json:"timestamp"`
	Version         string       `json:"version"`
	BuildDate       string       `json:"build_date"`
	Description     string       `json:"description"`
	PerformanceMode string       `json:"performance_mode"`
	UptimeSeconds   int          `json:"uptime_seconds"`
	Config          HealthConfig `json:"config"`
	Stats           HealthStats  `json:"stats"`
	Improvements    []string     `json:"improvements"`
}

type ErrorResponse struct {
	Error              string `json:"error"`
	Details            string `json:"details,omitempty"`
	RetryAfter         int    `json:"retry_after,omitempty"`
	AvailableEndpoints int    `json:"available_endpoints,omitempty"`
	PerformanceMode    string `json:"performance_mode,omitempty"`
}

// å…¨å±€é…ç½®
var (
	// åŸºç¡€é…ç½®
	upstreamURL   = getEnv("UPSTREAM_URL", "https://chat.z.ai/api/chat/completions")
	port          = getEnvInt("PORT", 8080)
	defaultKey    = getEnv("DEFAULT_KEY", "123456")
	upstreamToken = getEnv("UPSTREAM_TOKEN", "eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6Ijc3NWI4MjMyLTFjMDgtNDZjOC1iM2ZjLTc4NGZkOTYzOTFkMCIsImVtYWlsIjoiR3Vlc3QtMTc1NjQxNzIwODY2NkBndWVzdC5jb20ifQ.ANLFGzTOIhaocgsVRMtzhcHOfhvxWrf3RwiEV0b4mmeNMu72fIbp9j0D42aWlrupZN5AARqGPeIDUFU5po0gFQ")

	// æ¨¡å‹é…ç½®
	defaultModelName  = "GLM-4.5"
	thinkingModelName = "GLM-4.5-Thinking"
	searchModelName   = "GLM-4.5-Search"

	// ä¼ªè£…å‰ç«¯å¤´éƒ¨
	xFeVersion  = "prod-fe-1.0.70"
	browserUa   = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36 Edg/139.0.0.0"
	secChUa     = `"Not;A=Brand";v="99", "Microsoft Edge";v="139", "Chromium";v="139"`
	secChUaMob  = "?0"
	secChUaPlat = `"Windows"`
	originBase  = "https://chat.z.ai"

	// æ€§èƒ½é…ç½®
	performanceMode = getEnv("PERFORMANCE_MODE", "balanced")
	maxRetries      int
	retryDelay      int
	requestTimeout  int
	streamTimeout   int
	randomDelayMin  int
	randomDelayMax  int

	// æµå¤„ç†ä¼˜åŒ–é…ç½®
	streamBufferSize        = getEnvInt("STREAM_BUFFER_SIZE", 16384)
	disableConnectionCheck  = getEnv("DISABLE_CONNECTION_CHECK", "false") == "true"
	connectionCheckInterval = getEnvInt("CONNECTION_CHECK_INTERVAL", 20)

	// é«˜å¹¶å‘ç®¡ç†é…ç½®
	maxConcurrentConnections = getEnvInt("MAX_CONCURRENT_CONNECTIONS", 1000)
	connectionQueueSize      = getEnvInt("CONNECTION_QUEUE_SIZE", 500)
	maxConnectionTime        = getEnvInt("MAX_CONNECTION_TIME", 600000)
	memoryLimitMB            = getEnvInt("MEMORY_LIMIT_MB", 2048)
	enableMetrics            = getEnv("ENABLE_METRICS", "true") == "true"

	// åŠŸèƒ½é…ç½®
	anonTokenEnabled = getEnv("ANON_TOKEN_ENABLED", "true") == "true"
	thinkTagsMode    = getEnv("THINK_TAGS_MODE", "think")
	debugMode        = getEnv("DEBUG_MODE", "false") == "true"

	// ç»Ÿè®¡æ•°æ®
	requestCount      int64
	totalResponseTime int64
	errorCount        int64
	startTime         time.Time

	// å¹¶å‘æ§åˆ¶
	currentConnections  int64
	connectionSemaphore chan struct{}

	// æ—¥å¿—é…ç½®
	enableDetailedLogging = getEnv("ENABLE_DETAILED_LOGGING", "true") == "true"
	logUserMessages       = getEnv("LOG_USER_MESSAGES", "false") == "true"
	logResponseContent    = getEnv("LOG_RESPONSE_CONTENT", "false") == "true"

	// æ”¯æŒçš„æ¨¡å‹
	supportedModels = []Model{
		{ID: defaultModelName, Object: "model", Created: time.Now().Unix(), OwnedBy: "z.ai"},
		{ID: thinkingModelName, Object: "model", Created: time.Now().Unix(), OwnedBy: "z.ai"},
		{ID: searchModelName, Object: "model", Created: time.Now().Unix(), OwnedBy: "z.ai"},
	}

	// User-Agent åˆ—è¡¨
	userAgents = []string{
		"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
		"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
		"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
		"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
		"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0",
	}
)

// å·¥å…·å‡½æ•°
func getEnv(key, defaultValue string) string {
	if value := os.Getenv(key); value != "" {
		return value
	}
	return defaultValue
}

func getEnvInt(key string, defaultValue int) int {
	if value := os.Getenv(key); value != "" {
		if intValue, err := strconv.Atoi(value); err == nil {
			return intValue
		}
	}
	return defaultValue
}

func getPerformanceConfig() {
	mode := strings.ToLower(performanceMode)

	switch mode {
	case "fast":
		maxRetries = getEnvInt("MAX_RETRIES", 1)
		retryDelay = getEnvInt("RETRY_DELAY", 200)
		requestTimeout = getEnvInt("REQUEST_TIMEOUT", 10000)
		streamTimeout = getEnvInt("STREAM_TIMEOUT", 60000)
		randomDelayMin = getEnvInt("RANDOM_DELAY_MIN", 0)
		randomDelayMax = getEnvInt("RANDOM_DELAY_MAX", 100)
	case "secure":
		maxRetries = getEnvInt("MAX_RETRIES", 5)
		retryDelay = getEnvInt("RETRY_DELAY", 2000)
		requestTimeout = getEnvInt("REQUEST_TIMEOUT", 60000)
		streamTimeout = getEnvInt("STREAM_TIMEOUT", 600000)
		randomDelayMin = getEnvInt("RANDOM_DELAY_MIN", 500)
		randomDelayMax = getEnvInt("RANDOM_DELAY_MAX", 1500)
	default: // balanced
		maxRetries = getEnvInt("MAX_RETRIES", 3)
		retryDelay = getEnvInt("RETRY_DELAY", 1000)
		requestTimeout = getEnvInt("REQUEST_TIMEOUT", 120000)
		streamTimeout = getEnvInt("STREAM_TIMEOUT", 300000)
		randomDelayMin = getEnvInt("RANDOM_DELAY_MIN", 100)
		randomDelayMax = getEnvInt("RANDOM_DELAY_MAX", 500)
	}
}

func randomDelay() {
	if randomDelayMax > randomDelayMin {
		delay := mathrand.Intn(randomDelayMax-randomDelayMin) + randomDelayMin
		time.Sleep(time.Duration(delay) * time.Millisecond)
	}
}

func getRandomUserAgent() string {
	return userAgents[mathrand.Intn(len(userAgents))]
}

// æ—¥å¿—ç³»ç»Ÿå‡½æ•°
func generateRequestID() string {
	bytes := make([]byte, 8)
	if _, err := rand.Read(bytes); err != nil {
		return fmt.Sprintf("req_%d", time.Now().UnixNano())
	}
	return fmt.Sprintf("req_%s", hex.EncodeToString(bytes))
}

func maskAPIKey(apiKey string) string {
	if len(apiKey) <= 8 {
		return strings.Repeat("*", len(apiKey))
	}
	return apiKey[:4] + strings.Repeat("*", len(apiKey)-8) + apiKey[len(apiKey)-4:]
}

func getClientIP(r *http.Request) string {
	if xff := r.Header.Get("X-Forwarded-For"); xff != "" {
		ips := strings.Split(xff, ",")
		if len(ips) > 0 {
			return strings.TrimSpace(ips[0])
		}
	}

	if xri := r.Header.Get("X-Real-IP"); xri != "" {
		return xri
	}

	host, _, err := net.SplitHostPort(r.RemoteAddr)
	if err != nil {
		return r.RemoteAddr
	}
	return host
}

func logStructured(data interface{}) {
	if !enableDetailedLogging {
		return
	}

	jsonData, err := json.Marshal(data)
	if err != nil {
		log.Printf("æ—¥å¿—åºåˆ—åŒ–å¤±è´¥: %v", err)
		return
	}

	fmt.Println(string(jsonData))
}

func debugLog(format string, args ...interface{}) {
	if debugMode {
		log.Printf("[DEBUG] "+format, args...)
	}
}

func logRequest(requestID, clientIP, apiKey, model string, messageCount int, parameters interface{}, userAgent string) {
	if !enableDetailedLogging {
		return
	}

	requestLog := RequestLog{
		RequestID: requestID,
		Timestamp: time.Now().Format(time.RFC3339),
		Level:     LogLevelInfo,
		Type:      "request",
		ClientIP:  clientIP,
		APIKey:    maskAPIKey(apiKey),
		Model:     model,
		UserAgent: userAgent,
	}

	requestLog.Parameters = map[string]interface{}{
		"message_count": messageCount,
		"parameters":    parameters,
	}

	logStructured(requestLog)
}

func logResponse(requestID string, statusCode int, responseTime int64, endpoint string, retryCount int, errorMsg string) {
	if !enableDetailedLogging {
		return
	}

	level := LogLevelInfo
	if statusCode >= 400 {
		level = LogLevelError
	} else if statusCode >= 300 {
		level = LogLevelWarn
	}

	responseLog := ResponseLog{
		RequestID:    requestID,
		Timestamp:    time.Now().Format(time.RFC3339),
		Level:        level,
		Type:         "response",
		StatusCode:   statusCode,
		ResponseTime: responseTime,
		Endpoint:     endpoint,
		RetryCount:   retryCount,
		Error:        errorMsg,
	}

	logStructured(responseLog)
}

// è·å–åŒ¿åtokenï¼ˆæ¯æ¬¡å¯¹è¯ä½¿ç”¨ä¸åŒtokenï¼Œé¿å…å…±äº«è®°å¿†ï¼‰
func getAnonymousToken() (string, error) {
	client := &http.Client{Timeout: 10 * time.Second}
	req, err := http.NewRequest("GET", originBase+"/api/v1/auths/", nil)
	if err != nil {
		return "", err
	}

	// ä¼ªè£…æµè§ˆå™¨å¤´
	req.Header.Set("User-Agent", browserUa)
	req.Header.Set("Accept", "*/*")
	req.Header.Set("Accept-Language", "zh-CN,zh;q=0.9")
	req.Header.Set("X-FE-Version", xFeVersion)
	req.Header.Set("sec-ch-ua", secChUa)
	req.Header.Set("sec-ch-ua-mobile", secChUaMob)
	req.Header.Set("sec-ch-ua-platform", secChUaPlat)
	req.Header.Set("Origin", originBase)
	req.Header.Set("Referer", originBase+"/")

	resp, err := client.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("anon token status=%d", resp.StatusCode)
	}

	var body struct {
		Token string `json:"token"`
	}
	if err := json.NewDecoder(resp.Body).Decode(&body); err != nil {
		return "", err
	}

	if body.Token == "" {
		return "", fmt.Errorf("anon token empty")
	}

	return body.Token, nil
}

// æ€è€ƒå†…å®¹è½¬æ¢å‡½æ•°
func transformThinking(s string) string {
	// å» <summary>â€¦</summary>
	s = regexp.MustCompile(`(?s)<summary>.*?</summary>`).ReplaceAllString(s, "")
	// æ¸…ç†æ®‹ç•™è‡ªå®šä¹‰æ ‡ç­¾ï¼Œå¦‚ </thinking>ã€<Full> ç­‰
	s = strings.ReplaceAll(s, "</thinking>", "")
	s = strings.ReplaceAll(s, "<Full>", "")
	s = strings.ReplaceAll(s, "</Full>", "")
	s = strings.TrimSpace(s)

	switch thinkTagsMode {
	case "think":
		s = regexp.MustCompile(`<details[^>]*>`).ReplaceAllString(s, "<think>")
		s = strings.ReplaceAll(s, "</details>", "</think>")
	case "strip":
		s = regexp.MustCompile(`<details[^>]*>`).ReplaceAllString(s, "")
		s = strings.ReplaceAll(s, "</details>", "")
	}

	// å¤„ç†æ¯è¡Œå‰ç¼€ "> "ï¼ˆåŒ…æ‹¬èµ·å§‹ä½ç½®ï¼‰
	s = strings.TrimPrefix(s, "> ")
	s = strings.ReplaceAll(s, "\n> ", "\n")
	return strings.TrimSpace(s)
}

// å¸¦é‡è¯•çš„HTTPè¯·æ±‚
func requestWithRetry(ctx context.Context, upstreamReq UpstreamRequest, chatID, authToken string) (*http.Response, error) {
	var lastErr error

	reqBody, err := json.Marshal(upstreamReq)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: %v", err)
	}

	for i := 0; i < maxRetries; i++ {
		// æ·»åŠ å»¶è¿Ÿ
		if i > 0 {
			delay := time.Duration(retryDelay*int(math.Pow(2, float64(i)))) * time.Millisecond
			select {
			case <-time.After(delay):
			case <-ctx.Done():
				return nil, ctx.Err()
			}
		}

		randomDelay()

		// åˆ›å»ºè¯·æ±‚
		req, err := http.NewRequestWithContext(ctx, "POST", upstreamURL, bytes.NewReader(reqBody))
		if err != nil {
			lastErr = err
			continue
		}

		// è®¾ç½®è¯·æ±‚å¤´
		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("Accept", "application/json, text/event-stream")
		req.Header.Set("User-Agent", getRandomUserAgent())
		req.Header.Set("Authorization", "Bearer "+authToken)
		req.Header.Set("Accept-Language", "zh-CN")
		req.Header.Set("sec-ch-ua", secChUa)
		req.Header.Set("sec-ch-ua-mobile", secChUaMob)
		req.Header.Set("sec-ch-ua-platform", secChUaPlat)
		req.Header.Set("X-FE-Version", xFeVersion)
		req.Header.Set("Origin", originBase)
		req.Header.Set("Referer", originBase+"/c/"+chatID)

		debugLog("å°è¯•è¯·æ±‚ä¸Šæ¸¸: %s (ç¬¬%dæ¬¡å°è¯•)", upstreamURL, i+1)

		// å‘é€è¯·æ±‚
		client := &http.Client{
			Timeout: time.Duration(requestTimeout) * time.Millisecond,
		}

		resp, err := client.Do(req)
		if err != nil {
			lastErr = err
			debugLog("è¯·æ±‚å°è¯• %d/%d å¤±è´¥: %v", i+1, maxRetries, err)
			continue
		}

		if resp.StatusCode == http.StatusOK {
			debugLog("è¯·æ±‚æˆåŠŸ")
			return resp, nil
		}

		// å¤„ç†é™æµæˆ–å°ç¦é”™è¯¯
		if resp.StatusCode == http.StatusTooManyRequests || resp.StatusCode == http.StatusForbidden {
			waitTime := time.Duration(math.Min(float64(retryDelay)*math.Pow(2, float64(i)), 10000)) * time.Millisecond
			debugLog("è¢«é™æµæˆ–å°ç¦ (%d)ï¼Œç­‰å¾… %v åé‡è¯•...", resp.StatusCode, waitTime)
			resp.Body.Close()
			select {
			case <-time.After(waitTime):
			case <-ctx.Done():
				return nil, ctx.Err()
			}
			continue
		}

		resp.Body.Close()
		lastErr = fmt.Errorf("HTTP %d: %s", resp.StatusCode, resp.Status)
		debugLog("è¯·æ±‚å°è¯• %d/%d å¤±è´¥: %v", i+1, maxRetries, lastErr)
	}

	if lastErr == nil {
		lastErr = fmt.Errorf("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
	}
	return nil, lastErr
}

// HTTP å¤„ç†å‡½æ•°
func healthHandler(w http.ResponseWriter, r *http.Request) {
	avgResponseTime := int64(0)
	errorRate := 0
	if requestCount > 0 {
		avgResponseTime = totalResponseTime / requestCount
		errorRate = int((errorCount * 100) / requestCount)
	}

	uptime := time.Since(startTime)

	response := HealthResponse{
		Status:          "ok",
		Timestamp:       time.Now().Format(time.RFC3339),
		Version:         VERSION,
		BuildDate:       BUILD_DATE,
		Description:     DESCRIPTION,
		PerformanceMode: performanceMode,
		UptimeSeconds:   int(uptime.Seconds()),
		Config: HealthConfig{
			MaxRetries:             maxRetries,
			RetryDelay:             retryDelay,
			RequestTimeout:         requestTimeout,
			RandomDelay:            fmt.Sprintf("%d-%dms", randomDelayMin, randomDelayMax),
			MaxConcurrentConns:     maxConcurrentConnections,
			StreamBufferSize:       streamBufferSize,
			ConnectionCheckEnabled: !disableConnectionCheck,
		},
		Stats: HealthStats{
			TotalRequests:       requestCount,
			AverageResponseTime: avgResponseTime,
			ErrorRate:           errorRate,
			CurrentConnections:  atomic.LoadInt64(&currentConnections),
		},
		Improvements: []string{
			"åŸºäºåŸç‰ˆZ2APIçš„ä¼ä¸šçº§ä¼˜åŒ–",
			"å®Œæ•´çš„å¹¶å‘æ§åˆ¶æœºåˆ¶",
			"ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ",
			"æ€§èƒ½æ¨¡å¼é…ç½®",
			"é‡è¯•æœºåˆ¶å’Œé”™è¯¯æ¢å¤",
			"å¥åº·æ£€æŸ¥å’Œç›‘æ§",
			"åŒ¿åtokenæ”¯æŒ",
			"ä¸“ä¸šæ€è€ƒå†…å®¹å¤„ç†",
		},
	}

	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("Access-Control-Allow-Origin", "*")
	json.NewEncoder(w).Encode(response)
}

func modelsHandler(w http.ResponseWriter, r *http.Request) {
	response := ModelsResponse{
		Object: "list",
		Data:   supportedModels,
	}

	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("Access-Control-Allow-Origin", "*")
	json.NewEncoder(w).Encode(response)
}

func optionsHandler(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Access-Control-Allow-Origin", "*")
	w.Header().Set("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
	w.Header().Set("Access-Control-Allow-Headers", "Content-Type, Authorization")
	w.Header().Set("Access-Control-Allow-Credentials", "true")
	w.WriteHeader(http.StatusOK)
}

func chatHandler(w http.ResponseWriter, r *http.Request) {
	startTime := time.Now()
	atomic.AddInt64(&requestCount, 1)

	// ç”Ÿæˆè¯·æ±‚ ID
	requestID := generateRequestID()
	clientIP := getClientIP(r)
	userAgent := r.Header.Get("User-Agent")

	// è¯»å–è¯·æ±‚ä½“
	body, err := io.ReadAll(r.Body)
	if err != nil {
		atomic.AddInt64(&errorCount, 1)
		logResponse(requestID, http.StatusBadRequest, time.Since(startTime).Milliseconds(), "", 0, "Failed to read request body")
		http.Error(w, `{"error": "Failed to read request body"}`, http.StatusBadRequest)
		return
	}
	defer r.Body.Close()

	// API Key éªŒè¯
	auth := r.Header.Get("Authorization")
	key := strings.TrimPrefix(auth, "Bearer ")
	key = strings.TrimSpace(key)

	if key != defaultKey {
		atomic.AddInt64(&errorCount, 1)
		logResponse(requestID, http.StatusUnauthorized, time.Since(startTime).Milliseconds(), "", 0, "Unauthorized")
		w.Header().Set("Content-Type", "application/json")
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.WriteHeader(http.StatusUnauthorized)
		json.NewEncoder(w).Encode(ErrorResponse{Error: "Unauthorized"})
		return
	}

	debugLog("API keyéªŒè¯é€šè¿‡")

	// è§£æè¯·æ±‚ä½“
	var chatReq OpenAIRequest
	if err := json.Unmarshal(body, &chatReq); err != nil {
		atomic.AddInt64(&errorCount, 1)
		logResponse(requestID, http.StatusBadRequest, time.Since(startTime).Milliseconds(), "", 0, "Invalid JSON format")
		w.Header().Set("Content-Type", "application/json")
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.WriteHeader(http.StatusBadRequest)
		json.NewEncoder(w).Encode(ErrorResponse{Error: "Invalid JSON format"})
		return
	}

	debugLog("è¯·æ±‚è§£ææˆåŠŸ - æ¨¡å‹: %s, æµå¼: %v, æ¶ˆæ¯æ•°: %d", chatReq.Model, chatReq.Stream != nil && *chatReq.Stream, len(chatReq.Messages))

	// ç”Ÿæˆä¼šè¯ç›¸å…³ID
	chatID := fmt.Sprintf("%d-%d", time.Now().UnixNano(), time.Now().Unix())
	msgID := fmt.Sprintf("%d", time.Now().UnixNano())

	var isThinking bool
	var isSearch bool
	var searchMcp string
	if chatReq.Model == thinkingModelName {
		isThinking = true
	} else if chatReq.Model == searchModelName {
		isThinking = true
		isSearch = true
		searchMcp = "deep-web-search"
	}

	// è®°å½•è¯·æ±‚æ—¥å¿—
	parameters := map[string]interface{}{
		"stream":      chatReq.Stream,
		"temperature": chatReq.Temperature,
		"max_tokens":  chatReq.MaxTokens,
	}
	logRequest(requestID, clientIP, key, chatReq.Model, len(chatReq.Messages), parameters, userAgent)

	// æ„é€ ä¸Šæ¸¸è¯·æ±‚
	upstreamReq := UpstreamRequest{
		Stream:   true, // æ€»æ˜¯ä½¿ç”¨æµå¼ä»ä¸Šæ¸¸è·å–
		ChatID:   chatID,
		ID:       msgID,
		Model:    "0727-360B-API", // ä¸Šæ¸¸å®é™…æ¨¡å‹ID
		Messages: chatReq.Messages,
		Params:   map[string]interface{}{},
		Features: map[string]interface{}{
			"enable_thinking": isThinking,
			"web_search":      isSearch,
			"auto_web_search": isSearch,
		},
		BackgroundTasks: map[string]bool{
			"title_generation": false,
			"tags_generation":  false,
		},
		MCPServers:  []string{searchMcp},
		ToolServers: []string{},
		Variables: map[string]string{
			"{{USER_NAME}}":        "User",
			"{{USER_LOCATION}}":    "Unknown",
			"{{CURRENT_DATETIME}}": time.Now().Format("2006-01-02 15:04:05"),
		},
	}
	upstreamReq.ModelItem.ID = "0727-360B-API"
	upstreamReq.ModelItem.Name = "GLM-4.5"
	upstreamReq.ModelItem.OwnedBy = "openai"

	// é€‰æ‹©æœ¬æ¬¡å¯¹è¯ä½¿ç”¨çš„token
	authToken := upstreamToken
	if anonTokenEnabled {
		if t, err := getAnonymousToken(); err == nil {
			authToken = t
			debugLog("åŒ¿åtokenè·å–æˆåŠŸ: %s...", func() string {
				if len(t) > 10 {
					return t[:10]
				}
				return t
			}())
		} else {
			debugLog("åŒ¿åtokenè·å–å¤±è´¥ï¼Œå›é€€å›ºå®štoken: %v", err)
		}
	}

	isStream := chatReq.Stream != nil && *chatReq.Stream

	// å‘é€è¯·æ±‚åˆ°ä¸Šæ¸¸API
	timeoutDuration := time.Duration(requestTimeout) * time.Millisecond
	if isStream {
		timeoutDuration = time.Duration(streamTimeout) * time.Millisecond
		debugLog("ğŸŒŠ æµå¼è¯·æ±‚ï¼Œä½¿ç”¨æ‰©å±•è¶…æ—¶: %v", timeoutDuration)
	}

	ctx, cancel := context.WithTimeout(context.Background(), timeoutDuration)
	defer cancel()

	resp, err := requestWithRetry(ctx, upstreamReq, chatID, authToken)
	if err != nil {
		atomic.AddInt64(&errorCount, 1)
		responseTime := time.Since(startTime)
		atomic.AddInt64(&totalResponseTime, responseTime.Milliseconds())

		logResponse(requestID, http.StatusBadGateway, responseTime.Milliseconds(), "upstream", maxRetries, err.Error())
		debugLog("ä¸Šæ¸¸APIè¯·æ±‚å¤±è´¥: %v", err)
		w.Header().Set("Content-Type", "application/json")
		w.Header().Set("Access-Control-Allow-Origin", "*")
		w.WriteHeader(http.StatusBadGateway)
		json.NewEncoder(w).Encode(ErrorResponse{
			Error:           "External API request failed",
			Details:         err.Error(),
			RetryAfter:      60,
			PerformanceMode: performanceMode,
		})
		return
	}
	defer resp.Body.Close()

	// å¤„ç†å“åº”
	if !isStream {
		handleNonStreamResponse(w, resp, requestID, startTime)
	} else {
		handleStreamResponse(w, resp, requestID, startTime)
	}
}

// å¤„ç†éæµå¼å“åº”
func handleNonStreamResponse(w http.ResponseWriter, resp *http.Response, requestID string, startTime time.Time) {
	debugLog("å¼€å§‹å¤„ç†éæµå¼å“åº”")

	// æ”¶é›†å®Œæ•´å“åº”
	var fullContent strings.Builder
	scanner := bufio.NewScanner(resp.Body)

	for scanner.Scan() {
		line := scanner.Text()
		if !strings.HasPrefix(line, "data: ") {
			continue
		}

		dataStr := strings.TrimPrefix(line, "data: ")
		if dataStr == "" || dataStr == "[DONE]" {
			continue
		}

		var upstreamData UpstreamData
		if err := json.Unmarshal([]byte(dataStr), &upstreamData); err != nil {
			continue
		}

		if upstreamData.Data.DeltaContent != "" {
			out := upstreamData.Data.DeltaContent
			if upstreamData.Data.Phase == "thinking" {
				out = transformThinking(out)
			}
			if out != "" {
				fullContent.WriteString(out)
			}
		}

		if upstreamData.Data.Done || upstreamData.Data.Phase == "done" {
			debugLog("æ£€æµ‹åˆ°å®Œæˆä¿¡å·ï¼Œåœæ­¢æ”¶é›†")
			break
		}
	}

	finalContent := fullContent.String()
	debugLog("å†…å®¹æ”¶é›†å®Œæˆï¼Œæœ€ç»ˆé•¿åº¦: %d", len(finalContent))

	responseTime := time.Since(startTime)
	atomic.AddInt64(&totalResponseTime, responseTime.Milliseconds())

	logResponse(requestID, 200, responseTime.Milliseconds(), "upstream", 0, "")
	debugLog("éæµå¼å“åº”å®Œæˆ: %v", responseTime)

	// æ„é€ å®Œæ•´å“åº”
	response := OpenAIResponse{
		ID:      fmt.Sprintf("chatcmpl-%d", time.Now().Unix()),
		Object:  "chat.completion",
		Created: time.Now().Unix(),
		Model:   defaultModelName,
		Choices: []Choice{
			{
				Index: 0,
				Message: ChatMessage{
					Role:    "assistant",
					Content: finalContent,
				},
				FinishReason: "stop",
			},
		},
		Usage: &Usage{
			PromptTokens:     0,
			CompletionTokens: 0,
			TotalTokens:      0,
		},
	}

	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("Access-Control-Allow-Origin", "*")
	json.NewEncoder(w).Encode(response)
	debugLog("éæµå¼å“åº”å‘é€å®Œæˆ")
}

// å¤„ç†æµå¼å“åº” - ä¼˜åŒ–ç‰ˆæœ¬
func handleStreamResponse(w http.ResponseWriter, resp *http.Response, requestID string, startTime time.Time) {
	debugLog("å¼€å§‹å¤„ç†æµå¼å“åº”")

	w.Header().Set("Content-Type", "text/event-stream")
	w.Header().Set("Cache-Control", "no-cache")
	w.Header().Set("Connection", "keep-alive")
	w.Header().Set("Access-Control-Allow-Origin", "*")
	w.Header().Set("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
	w.Header().Set("Access-Control-Allow-Headers", "Content-Type, Authorization")

	flusher, ok := w.(http.Flusher)
	if !ok {
		http.Error(w, "Streaming unsupported", http.StatusInternalServerError)
		return
	}

	// å‘é€ç¬¬ä¸€ä¸ªchunkï¼ˆroleï¼‰
	firstChunk := OpenAIResponse{
		ID:      fmt.Sprintf("chatcmpl-%d", time.Now().Unix()),
		Object:  "chat.completion.chunk",
		Created: time.Now().Unix(),
		Model:   defaultModelName,
		Choices: []Choice{
			{
				Index: 0,
				Delta: Delta{Role: "assistant"},
			},
		},
	}
	writeSSEChunk(w, firstChunk)
	flusher.Flush()

	// ä½¿ç”¨ä¼˜åŒ–çš„ç¼“å†²åŒºå¤§å°
	buffer := make([]byte, streamBufferSize)
	lineBuffer := ""
	isInThinkBlock := false
	bufferedThinkContent := ""
	streamClosed := false
	checkCounter := 0
	sentInitialAnswer := false

	debugLog("ğŸŒŠ å¼€å§‹æµå¼å“åº”å¤„ç†ï¼Œç¼“å†²åŒºå¤§å°: %d bytes", streamBufferSize)

	for !streamClosed {
		// æ™ºèƒ½è¿æ¥æ£€æµ‹
		if !disableConnectionCheck {
			checkCounter++
			if checkCounter%connectionCheckInterval == 0 {
				if !isConnectionAlive(w) {
					debugLog("å®¢æˆ·ç«¯è¿æ¥å·²æ–­å¼€ï¼Œåœæ­¢æµå¼ä¼ è¾“")
					break
				}
			}
		}

		n, err := resp.Body.Read(buffer)
		if n > 0 {
			chunk := string(buffer[:n])
			lineBuffer += chunk

			// é˜²æ­¢è¡Œç¼“å†²åŒºè¿‡å¤§
			if len(lineBuffer) > 1024*1024 {
				debugLog("è­¦å‘Šï¼šè¡Œç¼“å†²åŒºè¿‡å¤§ (%d bytes)", len(lineBuffer))
				if idx := strings.LastIndex(lineBuffer[:len(lineBuffer)/2], "\n"); idx > 0 {
					lineBuffer = lineBuffer[idx+1:]
				}
			}

			// å¤„ç†ç¼“å†²åŒºä¸­çš„å®Œæ•´è¡Œ
			for {
				lineEnd := strings.Index(lineBuffer, "\n")
				if lineEnd == -1 {
					break
				}

				line := lineBuffer[:lineEnd]
				lineBuffer = lineBuffer[lineEnd+1:]

				if !streamClosed {
					processStreamLine(line, &isInThinkBlock, &bufferedThinkContent, &streamClosed, &sentInitialAnswer, w, flusher)
				}

				if streamClosed {
					break
				}
			}
		}

		if err != nil {
			if err == io.EOF {
				if lineBuffer != "" && !streamClosed {
					processStreamLine(lineBuffer, &isInThinkBlock, &bufferedThinkContent, &streamClosed, &sentInitialAnswer, w, flusher)
				}
				break
			}
			debugLog("è¯»å–æµæ•°æ®å¤±è´¥: %v", err)
			break
		}
	}

	// ç¡®ä¿å‘é€æœ€åçš„æ€è€ƒå†…å®¹
	if isInThinkBlock && bufferedThinkContent != "" {
		sendThinkContentSafe(bufferedThinkContent, w, flusher)
	}

	debugLog("æµå¼å“åº”å¤„ç†å®Œæˆ")
}

// è¾…åŠ©å‡½æ•°
func writeSSEChunk(w http.ResponseWriter, chunk OpenAIResponse) {
	data, _ := json.Marshal(chunk)
	fmt.Fprintf(w, "data: %s\n\n", data)
}

func isConnectionAlive(w http.ResponseWriter) bool {
	if _, err := fmt.Fprint(w, ""); err != nil {
		return false
	}
	return true
}

func processStreamLine(line string, isInThinkBlock *bool, bufferedThinkContent *string, streamClosed *bool, sentInitialAnswer *bool, w http.ResponseWriter, flusher http.Flusher) {
	line = strings.TrimSpace(line)

	if strings.HasPrefix(line, "data: ") {
		jsonText := strings.TrimSpace(line[6:])

		if jsonText == "[DONE]" {
			// å‘é€ç¼“å­˜çš„æ€è€ƒå†…å®¹
			if *isInThinkBlock && *bufferedThinkContent != "" {
				sendThinkContentSafe(*bufferedThinkContent, w, flusher)
			}

			// å®‰å…¨å‘é€ç»“æŸæ ‡è®°
			if err := sendDataSafe("data: [DONE]\n\n", w, flusher); err != nil {
				debugLog("å‘é€ç»“æŸæ ‡è®°å¤±è´¥: %v", err)
			}
			*streamClosed = true
			return
		}

		if jsonText != "" {
			var upstreamData UpstreamData
			if err := json.Unmarshal([]byte(jsonText), &upstreamData); err != nil {
				debugLog("JSON è§£æå¤±è´¥ï¼Œè·³è¿‡æ­¤æ•°æ®: %v", err)
				return
			}

			// é”™è¯¯æ£€æµ‹
			if upstreamData.Error != nil || upstreamData.Data.Error != nil ||
				(upstreamData.Data.Inner != nil && upstreamData.Data.Inner.Error != nil) {
				debugLog("ä¸Šæ¸¸é”™è¯¯ï¼Œç»“æŸæµ")
				endChunk := OpenAIResponse{
					ID:      fmt.Sprintf("chatcmpl-%d", time.Now().Unix()),
					Object:  "chat.completion.chunk",
					Created: time.Now().Unix(),
					Model:   defaultModelName,
					Choices: []Choice{{Index: 0, Delta: Delta{}, FinishReason: "stop"}},
				}
				writeSSEChunk(w, endChunk)
				fmt.Fprintf(w, "data: [DONE]\n\n")
				flusher.Flush()
				*streamClosed = true
				return
			}

			// å¤„ç†EditContentåœ¨æœ€åˆçš„answerä¿¡æ¯ï¼ˆåªå‘é€ä¸€æ¬¡ï¼‰
			if !*sentInitialAnswer && upstreamData.Data.EditContent != "" && upstreamData.Data.Phase == "answer" {
				out := upstreamData.Data.EditContent
				if out != "" {
					parts := regexp.MustCompile(`</details>`).Split(out, -1)
					if len(parts) > 1 {
						content := parts[1]
						if content != "" {
							debugLog("å‘é€åˆå§‹ç­”æ¡ˆå†…å®¹")
							chunk := OpenAIResponse{
								ID:      fmt.Sprintf("chatcmpl-%d", time.Now().Unix()),
								Object:  "chat.completion.chunk",
								Created: time.Now().Unix(),
								Model:   defaultModelName,
								Choices: []Choice{{Index: 0, Delta: Delta{Content: content}}},
							}
							writeSSEChunk(w, chunk)
							flusher.Flush()
							*sentInitialAnswer = true
						}
					}
				}
			}

			if upstreamData.Data.DeltaContent != "" {
				out := upstreamData.Data.DeltaContent
				if upstreamData.Data.Phase == "thinking" {
					out = transformThinking(out)
					// æ€è€ƒå†…å®¹ä½¿ç”¨ reasoning_content å­—æ®µ
					if out != "" {
						debugLog("å‘é€æ€è€ƒå†…å®¹")
						chunk := OpenAIResponse{
							ID:      fmt.Sprintf("chatcmpl-%d", time.Now().Unix()),
							Object:  "chat.completion.chunk",
							Created: time.Now().Unix(),
							Model:   defaultModelName,
							Choices: []Choice{{Index: 0, Delta: Delta{ReasoningContent: out}}},
						}
						writeSSEChunk(w, chunk)
						flusher.Flush()
					}
				} else {
					// æ™®é€šå†…å®¹ä½¿ç”¨ content å­—æ®µ
					if out != "" {
						debugLog("å‘é€æ™®é€šå†…å®¹")
						chunk := OpenAIResponse{
							ID:      fmt.Sprintf("chatcmpl-%d", time.Now().Unix()),
							Object:  "chat.completion.chunk",
							Created: time.Now().Unix(),
							Model:   defaultModelName,
							Choices: []Choice{{Index: 0, Delta: Delta{Content: out}}},
						}
						writeSSEChunk(w, chunk)
						flusher.Flush()
					}
				}
			}

			// æ£€æŸ¥æ˜¯å¦ç»“æŸ
			if upstreamData.Data.Done || upstreamData.Data.Phase == "done" {
				debugLog("æ£€æµ‹åˆ°æµç»“æŸä¿¡å·")
				// å‘é€ç»“æŸchunk
				endChunk := OpenAIResponse{
					ID:      fmt.Sprintf("chatcmpl-%d", time.Now().Unix()),
					Object:  "chat.completion.chunk",
					Created: time.Now().Unix(),
					Model:   defaultModelName,
					Choices: []Choice{{Index: 0, Delta: Delta{}, FinishReason: "stop"}},
				}
				writeSSEChunk(w, endChunk)
				flusher.Flush()

				// å‘é€[DONE]
				fmt.Fprintf(w, "data: [DONE]\n\n")
				flusher.Flush()
				debugLog("æµå¼å“åº”å®Œæˆ")
				*streamClosed = true
			}
		}
	}
}

// å®‰å…¨å‘é€æ•°æ®çš„é€šç”¨å‡½æ•°
func sendDataSafe(data string, w http.ResponseWriter, flusher http.Flusher) error {
	defer func() {
		if r := recover(); r != nil {
			debugLog("å‘é€æ•°æ®æ—¶å‘ç”Ÿ panic: %v", r)
		}
	}()

	_, err := fmt.Fprint(w, data)
	if err != nil {
		return fmt.Errorf("å†™å…¥å“åº”å¤±è´¥: %v", err)
	}

	if flusher != nil {
		flusher.Flush()
	}
	return nil
}

// å‘é€æ€è€ƒå†…å®¹ - å®‰å…¨ç‰ˆæœ¬
func sendThinkContentSafe(content string, w http.ResponseWriter, flusher http.Flusher) {
	thinkChunk := OpenAIResponse{
		ID:      fmt.Sprintf("chatcmpl-%d", time.Now().Unix()),
		Object:  "chat.completion.chunk",
		Created: time.Now().Unix(),
		Model:   defaultModelName,
		Choices: []Choice{{Index: 0, Delta: Delta{Content: fmt.Sprintf("<think>%s</think>", content)}}},
	}

	thinkJSON, err := json.Marshal(thinkChunk)
	if err != nil {
		debugLog("æ€è€ƒå†…å®¹ JSON ç¼–ç å¤±è´¥: %v", err)
		return
	}

	data := fmt.Sprintf("data: %s\n\n", string(thinkJSON))
	if err := sendDataSafe(data, w, flusher); err != nil {
		debugLog("å‘é€æ€è€ƒå†…å®¹å¤±è´¥: %v", err)
	}
}

// å¹¶å‘æ§åˆ¶ä¸­é—´ä»¶
func concurrencyControlMiddleware(next http.HandlerFunc) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		select {
		case connectionSemaphore <- struct{}{}:
			atomic.AddInt64(&currentConnections, 1)
			defer func() {
				<-connectionSemaphore
				atomic.AddInt64(&currentConnections, -1)
			}()
			next(w, r)
		default:
			http.Error(w, `{"error": "Server too busy, please try again later"}`, http.StatusServiceUnavailable)
			debugLog("âš ï¸ è¿æ¥æ•°å·²æ»¡ï¼Œæ‹’ç»æ–°è¿æ¥ã€‚å½“å‰è¿æ¥æ•°: %d", atomic.LoadInt64(&currentConnections))
		}
	}
}

// è·å–å½“å‰ç³»ç»ŸçŠ¶æ€
func getSystemStatus() map[string]interface{} {
	var m runtime.MemStats
	runtime.ReadMemStats(&m)

	return map[string]interface{}{
		"current_connections": atomic.LoadInt64(&currentConnections),
		"max_connections":     maxConcurrentConnections,
		"memory_usage_mb":     m.Alloc / 1024 / 1024,
		"memory_limit_mb":     memoryLimitMB,
		"total_requests":      atomic.LoadInt64(&requestCount),
		"error_count":         atomic.LoadInt64(&errorCount),
		"uptime_seconds":      int(time.Since(startTime).Seconds()),
	}
}

// çŠ¶æ€ç›‘æ§å¤„ç†å™¨
func statusHandler(w http.ResponseWriter, r *http.Request) {
	status := getSystemStatus()
	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("Access-Control-Allow-Origin", "*")
	json.NewEncoder(w).Encode(status)
}

// åˆå§‹åŒ–å‡½æ•°
func init() {
	// è®¾ç½®éšæœºç§å­
	mathrand.Seed(time.Now().UnixNano())

	// åˆå§‹åŒ–æ€§èƒ½é…ç½®
	getPerformanceConfig()

	// åˆå§‹åŒ–å¹¶å‘æ§åˆ¶
	connectionSemaphore = make(chan struct{}, maxConcurrentConnections)

	// è®°å½•å¯åŠ¨æ—¶é—´
	startTime = time.Now()

	log.Printf("ğŸš€ Z2API Goä¼˜åŒ–ç‰ˆ v%s (æ„å»ºæ—¥æœŸ: %s)", VERSION, BUILD_DATE)
	log.Printf("ğŸ“ %s", DESCRIPTION)
	log.Printf("âš¡ æ€§èƒ½æ¨¡å¼: %s", performanceMode)
	log.Printf("ğŸ”§ é…ç½®è¯¦æƒ…:")
	log.Printf("   - æœ€å¤§é‡è¯•æ¬¡æ•°: %d", maxRetries)
	log.Printf("   - é‡è¯•å»¶è¿Ÿ: %dms", retryDelay)
	log.Printf("   - è¯·æ±‚è¶…æ—¶: %dms", requestTimeout)
	log.Printf("   - æµå¼è¶…æ—¶: %dms", streamTimeout)
	log.Printf("   - éšæœºå»¶è¿Ÿ: %d-%dms", randomDelayMin, randomDelayMax)
	log.Printf("ğŸ”— å¹¶å‘æ§åˆ¶:")
	log.Printf("   - æœ€å¤§å¹¶å‘è¿æ¥: %d", maxConcurrentConnections)
	log.Printf("   - è¿æ¥é˜Ÿåˆ—å¤§å°: %d", connectionQueueSize)
	log.Printf("   - æœ€å¤§è¿æ¥æ—¶é—´: %dms", maxConnectionTime)
	log.Printf("ğŸŒŠ æµå¤„ç†ä¼˜åŒ–:")
	log.Printf("   - ç¼“å†²åŒºå¤§å°: %d bytes", streamBufferSize)
	log.Printf("   - è¿æ¥æ£€æµ‹: %v (é—´éš”: %d)", !disableConnectionCheck, connectionCheckInterval)
	log.Printf("ğŸ’¾ å†…å­˜ç®¡ç†:")
	log.Printf("   - å†…å­˜é™åˆ¶: %dMB", memoryLimitMB)
	log.Printf("   - æŒ‡æ ‡æ”¶é›†: %v", enableMetrics)
	log.Printf("ğŸ“ æ—¥å¿—é…ç½®:")
	log.Printf("   - è¯¦ç»†æ—¥å¿—: %v", enableDetailedLogging)
	log.Printf("   - ç”¨æˆ·æ¶ˆæ¯: %v", logUserMessages)
	log.Printf("   - å“åº”å†…å®¹: %v", logResponseContent)
	log.Printf("ğŸ” åŠŸèƒ½é…ç½®:")
	log.Printf("   - åŒ¿åtoken: %v", anonTokenEnabled)
	log.Printf("   - æ€è€ƒæ ‡ç­¾æ¨¡å¼: %s", thinkTagsMode)
	log.Printf("   - è°ƒè¯•æ¨¡å¼: %v", debugMode)
	log.Printf("ğŸ¯ æ”¯æŒæ¨¡å‹: %s", func() string {
		var models []string
		for _, model := range supportedModels {
			models = append(models, model.ID)
		}
		return strings.Join(models, ", ")
	}())
}

func main() {
	// è®¾ç½®è·¯ç”±
	http.HandleFunc("/health", healthHandler)
	http.HandleFunc("/status", statusHandler)
	http.HandleFunc("/v1/models", modelsHandler)
	http.HandleFunc("/v1/chat/completions", concurrencyControlMiddleware(chatHandler))
	http.HandleFunc("/", optionsHandler)

	// å¯åŠ¨æœåŠ¡å™¨
	addr := fmt.Sprintf(":%d", port)
	log.Printf("ğŸŒ æœåŠ¡å™¨å¯åŠ¨åœ¨ç«¯å£ %d", port)
	log.Printf("ğŸ“Š å¥åº·æ£€æŸ¥: http://localhost:%d/health", port)
	log.Printf("ğŸ“ˆ çŠ¶æ€ç›‘æ§: http://localhost:%d/status", port)
	log.Printf("ğŸ¯ æ¨¡å‹åˆ—è¡¨: http://localhost:%d/v1/models", port)
	log.Printf("ğŸ’¬ èŠå¤©æ¥å£: http://localhost:%d/v1/chat/completions", port)
	log.Printf("ğŸ”‘ APIå¯†é’¥: %s", maskAPIKey(defaultKey))
	log.Printf("ğŸ”— ä¸Šæ¸¸åœ°å€: %s", upstreamURL)

	// å¯åŠ¨æ€§èƒ½ç›‘æ§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	if enableMetrics {
		go func() {
			ticker := time.NewTicker(30 * time.Second)
			defer ticker.Stop()

			for range ticker.C {
				status := getSystemStatus()
				debugLog("ğŸ“Š ç³»ç»ŸçŠ¶æ€: è¿æ¥æ•°=%d/%d, å†…å­˜=%dMB/%dMB, è¯·æ±‚æ•°=%d, é”™è¯¯æ•°=%d",
					status["current_connections"], status["max_connections"],
					status["memory_usage_mb"], status["memory_limit_mb"],
					status["total_requests"], status["error_count"])

				// å†…å­˜ä½¿ç”¨æ£€æŸ¥
				if memUsage, ok := status["memory_usage_mb"].(uint64); ok && memUsage > uint64(memoryLimitMB) {
					log.Printf("âš ï¸ å†…å­˜ä½¿ç”¨è¶…è¿‡é™åˆ¶: %dMB > %dMB", memUsage, memoryLimitMB)
					runtime.GC() // å¼ºåˆ¶åƒåœ¾å›æ”¶
				}
			}
		}()
	}

	// ä¼˜é›…å…³é—­å¤„ç†
	log.Printf("âœ… Z2API Goä¼˜åŒ–ç‰ˆå¯åŠ¨å®Œæˆï¼")
	log.Printf("ğŸ‰ ç›¸æ¯”åŸç‰ˆçš„æ”¹è¿›:")
	log.Printf("   âœ… ä¼ä¸šçº§å¹¶å‘æ§åˆ¶")
	log.Printf("   âœ… å®Œæ•´çš„ç»“æ„åŒ–æ—¥å¿—")
	log.Printf("   âœ… æ€§èƒ½æ¨¡å¼é…ç½®")
	log.Printf("   âœ… é‡è¯•æœºåˆ¶å’Œé”™è¯¯æ¢å¤")
	log.Printf("   âœ… å¥åº·æ£€æŸ¥å’Œç›‘æ§")
	log.Printf("   âœ… ä¼˜åŒ–çš„æµå¼å“åº”å¤„ç†")
	log.Printf("   âœ… å†…å­˜ç®¡ç†å’Œæ³„æ¼é˜²æŠ¤")
	log.Printf("   âœ… æ™ºèƒ½è¿æ¥æ£€æµ‹")
	log.Printf("   âœ… ä¿æŒåŸç‰ˆçš„åŒ¿åtokenå’Œæ€è€ƒå¤„ç†ç‰¹æ€§")

	if err := http.ListenAndServe(addr, nil); err != nil {
		log.Fatalf("âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: %v", err)
	}
}
